name: CI

on:
  push:
    branches: [main]
    paths:
      - 'EpisodicRAG/**'
  pull_request:
    branches: [main]
    paths:
      - 'EpisodicRAG/**'

jobs:
  lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install ruff
        run: pip install ruff

      - name: Run ruff linter
        working-directory: EpisodicRAG
        run: ruff check scripts/

      - name: Run ruff formatter check
        working-directory: EpisodicRAG
        run: ruff format --check scripts/

  type-check:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install mypy
        run: pip install mypy

      - name: Run mypy
        working-directory: EpisodicRAG
        run: mypy scripts/
        continue-on-error: true

  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.10', '3.11', '3.12']

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e EpisodicRAG[dev]

      - name: Run tests with coverage
        working-directory: EpisodicRAG
        run: |
          # Run all tests for coverage calculation
          python -m pytest --cov-report=xml --cov-fail-under=80 -v 2>&1 | tee pytest_output.txt
          # Extract test count from pytest summary line (e.g., "556 passed")
          TEST_COUNT=$(grep -oP '\d+(?= passed)' pytest_output.txt | head -1 || echo "0")
          echo "TEST_COUNT=$TEST_COUNT" >> $GITHUB_ENV
          echo "Detected $TEST_COUNT tests"

      - name: Generate test badge JSON
        if: matrix.python-version == '3.11'
        working-directory: EpisodicRAG
        run: |
          echo "{\"schemaVersion\":1,\"label\":\"tests\",\"message\":\"$TEST_COUNT passed\",\"color\":\"brightgreen\"}" > test_badge.json
          cat test_badge.json

      - name: Upload test badge to Gist
        if: matrix.python-version == '3.11' && github.ref == 'refs/heads/main' && github.event_name == 'push'
        uses: exuanbo/actions-deploy-gist@v1
        with:
          token: ${{ secrets.GIST_TOKEN }}
          gist_id: ${{ vars.TEST_BADGE_GIST_ID }}
          file_path: EpisodicRAG/test_badge.json
          file_type: text

      - name: Upload test results artifact
        if: matrix.python-version == '3.11'
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: |
            EpisodicRAG/pytest_output.txt
            EpisodicRAG/coverage.xml

      - name: Upload coverage to Codecov
        if: matrix.python-version == '3.11'
        uses: codecov/codecov-action@v4
        with:
          file: EpisodicRAG/coverage.xml
          fail_ci_if_error: false

  performance:
    runs-on: ubuntu-latest
    needs: test
    # Run on main branch push or PR (optional for PRs)
    if: github.ref == 'refs/heads/main' || github.event_name == 'pull_request'

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e EpisodicRAG[dev]

      - name: Run performance tests
        working-directory: EpisodicRAG
        run: |
          echo "Running performance and slow tests..."
          python -m pytest -m "slow or performance" --no-cov -v --tb=short 2>&1 | tee perf_output.txt

          # Check for failures (exit code)
          PERF_RESULT=$?

          # Count passed/failed
          PASSED=$(grep -oP '\d+(?= passed)' perf_output.txt | head -1 || echo "0")
          FAILED=$(grep -oP '\d+(?= failed)' perf_output.txt | head -1 || echo "0")

          echo "Performance tests: $PASSED passed, $FAILED failed"

          # Fail if any performance test failed (10% regression threshold is enforced in test assertions)
          if [ "$FAILED" != "0" ]; then
            echo "::error::Performance regression detected! $FAILED test(s) failed."
            exit 1
          fi

          exit $PERF_RESULT

      - name: Upload performance results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: performance-results
          path: EpisodicRAG/perf_output.txt
