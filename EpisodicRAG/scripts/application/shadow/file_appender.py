#!/usr/bin/env python3
"""
File Appender
=============

ファイル追加処理（Shadowへの増分追加）
"""

from pathlib import Path
from typing import Dict, List, Set

from domain.constants import SOURCE_TYPE_LOOPS
from domain.types import LevelHierarchyEntry, OverallDigestData, ShadowDigestData
from domain.validators import is_valid_dict, is_valid_overall_digest
from infrastructure import (
    get_structured_logger,
    log_warning,
    try_read_json_from_file,
)

from .file_detector import FileDetector
from .placeholder_manager import PlaceholderManager
from .shadow_io import ShadowIO
from .template import ShadowTemplate

# 構造化ロガー
_logger = get_structured_logger(__name__)


class FileAppender:
    """ファイル追加処理クラス"""

    def __init__(
        self,
        shadow_io: ShadowIO,
        file_detector: FileDetector,
        template: ShadowTemplate,
        level_hierarchy: Dict[str, LevelHierarchyEntry],
        placeholder_manager: PlaceholderManager,
    ):
        """
        初期化

        Args:
            shadow_io: ShadowIO インスタンス
            file_detector: FileDetector インスタンス
            template: ShadowTemplate インスタンス
            level_hierarchy: レベル階層情報
            placeholder_manager: PlaceholderManager インスタンス
        """
        self.shadow_io = shadow_io
        self.file_detector = file_detector
        self.template = template
        self.level_hierarchy = level_hierarchy
        self.placeholder_manager = placeholder_manager

    def _ensure_overall_digest_initialized(
        self, shadow_data: ShadowDigestData, level: str
    ) -> OverallDigestData:
        """
        overall_digestの初期化を確保

        Args:
            shadow_data: ShadowGrandDigestデータ
            level: レベル名

        Returns:
            初期化済みのoverall_digest
        """
        overall_digest = shadow_data["latest_digests"][level]["overall_digest"]

        _logger.state("_ensure_overall_digest_initialized", level=level)
        _logger.validation(
            "overall_digest",
            is_none=overall_digest is None,
            is_valid=is_valid_overall_digest(overall_digest, require_non_empty=False),
        )

        # 単一条件で初期化判定（dictかつsource_files存在）
        # file_appender では空のsource_filesも許容（後でファイルを追加するため）
        if not is_valid_overall_digest(overall_digest, require_non_empty=False):
            _logger.decision("reinitializing overall_digest (invalid or missing source_files)")
            initialized = self.template.create_empty_overall_digest()
            shadow_data["latest_digests"][level]["overall_digest"] = initialized
            return initialized

        # is_valid_overall_digest は TypeGuard なので、
        # この時点で overall_digest は OverallDigestData 型に絞り込まれている
        return overall_digest

    def _add_new_files_to_digest(
        self,
        overall_digest: OverallDigestData,
        new_files: List[Path],
        existing_files: Set[str],
    ) -> int:
        """
        新規ファイルをoverall_digestに追加

        Args:
            overall_digest: 追加先のダイジェスト
            new_files: 追加候補のファイルリスト
            existing_files: 既存ファイル名のセット

        Returns:
            追加されたファイル数
        """
        added_count = 0
        for file_path in new_files:
            if file_path.name not in existing_files:
                overall_digest["source_files"].append(file_path.name)
                added_count += 1
                _logger.info(f"  + {file_path.name}")
            else:
                _logger.file_op("skipped (already exists)", file=file_path.name)
        return added_count

    def _log_digest_contents_for_level(
        self,
        new_files: List[Path],
        existing_files: Set[str],
        level: str,
        source_type: str,
    ) -> None:
        """
        Monthly以上のレベルでDigestファイル内容をログ出力

        Args:
            new_files: 追加されたファイルリスト
            existing_files: 既存ファイル名のセット
            level: レベル名
            source_type: ソースタイプ
        """
        if source_type == SOURCE_TYPE_LOOPS:
            return

        for file_path in new_files:
            if file_path.name not in existing_files:
                self._log_digest_content(file_path, level)

    def _log_digest_content(self, file_path: Path, level: str) -> None:
        """
        Digestファイルの内容を読み込んでログ出力（Monthly以上用）

        Args:
            file_path: ファイルパス
            level: レベル名
        """
        source_dir = self.file_detector.get_source_path(level)
        full_path = source_dir / file_path.name

        digest_data = try_read_json_from_file(full_path)
        if digest_data is None:
            return

        if not is_valid_dict(digest_data):
            log_warning(f"{file_path.name} is not a dict, skipping")
            return

        overall_raw = digest_data.get("overall_digest")
        overall = overall_raw if isinstance(overall_raw, dict) else {}

        _logger.info(f"ダイジェスト内容を読込: {file_path.name}")
        _logger.info(f"      - digest_type: {overall.get('digest_type', 'N/A')}")
        _logger.info(f"      - keywords: {len(overall.get('keywords', []))}件")
        _logger.info(f"      - abstract: {len(overall.get('abstract', ''))}文字")
        _logger.info(f"      - impression: {len(overall.get('impression', ''))}文字")

    def add_files_to_shadow(self, level: str, new_files: List[Path]) -> None:
        """
        指定レベルのShadowに新しいファイルを追加（増分更新）

        Weekly: source_filesのみ追加（PLACEHOLDERのまま）→ Claude分析待ち
        Monthly以上: Digestファイル内容を読み込んでログ出力（まだらボケ回避）

        Args:
            level: レベル名
            new_files: 追加するファイルのリスト

        Example:
            >>> appender.add_files_to_shadow("weekly", [Path("L00186.txt")])
            # shadow["weekly"]["source_files"]に"L00186.txt"が追加される
        """
        shadow_data = self.shadow_io.load_or_create()
        overall_digest = self._ensure_overall_digest_initialized(shadow_data, level)

        existing_files = set(overall_digest["source_files"])
        source_type = self.level_hierarchy[level]["source"]

        _logger.state(
            "add_files_to_shadow",
            level=level,
            new_files_count=len(new_files),
            existing_files_count=len(existing_files),
            source_type=source_type,
        )

        # ファイル追加
        added_count = self._add_new_files_to_digest(overall_digest, new_files, existing_files)

        # ログ出力（Monthly以上）
        self._log_digest_contents_for_level(new_files, existing_files, level, source_type)

        _logger.state("files_added", count=added_count)

        # PLACEHOLDERの更新または既存分析の保持
        total_files = len(overall_digest["source_files"])
        _logger.state("total_files_after_add", total=total_files)
        self.placeholder_manager.update_or_preserve(overall_digest, total_files)

        self.shadow_io.save(shadow_data)
